
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Fusion++ · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-multipart/multipart.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-image-captions/image-captions.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-donate/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-advanced-emoji/emoji-website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-terminal/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-codeblock-filename/block.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    


    

        
    
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="SLAM++.html" />
    
    
    <link rel="prev" href="slam-with-objects-using-a-nonparametric-pose-graph.html" />
    

    
    <link rel="stylesheet" href="gitbook/gitbook-plugin-chart/c3/c3.min.css">
    <script src="gitbook/gitbook-plugin-chart/c3/d3.min.js"></script>
    <script src="gitbook/gitbook-plugin-chart/c3/c3.min.js"></script>
    

    <script src="gitbook/gitbook-plugin-graph/d3.min.js"></script>
    <script src="gitbook/gitbook-plugin-graph/function-plot.js"></script>    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Overview</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    About
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="SLAM-Introduction.html">
            
                <a href="SLAM-Introduction.html">
            
                    
                    SLAM Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="SLAM-Resources.html">
            
                <a href="SLAM-Resources.html">
            
                    
                    SLAM Resources
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="Software.html">
            
                <a href="Software.html">
            
                    
                    SLAM Software
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Math Foundamentals</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="Coordinate_System.html">
            
                <a href="Coordinate_System.html">
            
                    
                    Coordinate_System
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="Recursive_Bayes_Filter.html">
            
                <a href="Recursive_Bayes_Filter.html">
            
                    
                    Recursive Bayes Filter
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">AI SLAM</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="AI-SLAM-Summary.html">
            
                <a href="AI-SLAM-Summary.html">
            
                    
                    AI SLAM Summary
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="slam-with-objects-using-a-nonparametric-pose-graph.html">
            
                <a href="slam-with-objects-using-a-nonparametric-pose-graph.html">
            
                    
                    Slam with objects using a nonparametric pose graph
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="3.3" data-path="Fusion++.html">
            
                <a href="Fusion++.html">
            
                    
                    Fusion++
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="SLAM++.html">
            
                <a href="SLAM++.html">
            
                    
                    SLAM++
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="Monocular-Object-and-Plane-SLAM-in-Structured-Environments.html">
            
                <a href="Monocular-Object-and-Plane-SLAM-in-Structured-Environments.html">
            
                    
                    Monocular Object and Plane SLAM in Structured Environments
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="CubeSLAM.html">
            
                <a href="CubeSLAM.html">
            
                    
                    CubeSLAM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.7" data-path="SSFM.html">
            
                <a href="SSFM.html">
            
                    
                    SSFM
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Traditional SLAM</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="ORB-SLAM.html">
            
                <a href="ORB-SLAM.html">
            
                    
                    ORB-SLAM
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">lidar</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="lidar.html">
            
                <a href="lidar.html">
            
                    
                    lidar
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="graph-slam.html">
            
                <a href="graph-slam.html">
            
                    
                    graph slam
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ML,DL</li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="Mask-RCNN.html">
            
                <a href="Mask-RCNN.html">
            
                    
                    Mask-RCNN
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Tools</li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="ros.html">
            
                <a href="ros.html">
            
                    
                    ros
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="kinect2.html">
            
                <a href="kinect2.html">
            
                    
                    kinect2
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Video Courses - Robot & SLAM & AI</li>
        
        
    
        <li class="chapter " data-level="8.1" data-path="小象学院slam无人驾驶学习笔记.html">
            
                <a href="小象学院slam无人驾驶学习笔记.html">
            
                    
                    小象学院slam无人驾驶学习笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="机器人视觉与控制学习笔记.html">
            
                <a href="机器人视觉与控制学习笔记.html">
            
                    
                    机器人视觉与控制学习笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.3" data-path="slam-course-robot-mapping.html">
            
                <a href="slam-course-robot-mapping.html">
            
                    
                    SLAM-Course-Robot Mapping
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Fusion++</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="2018-fusion-volumetric-object-level-slam">2018-Fusion++: Volumetric Object-Level SLAM</h1>
<h2 id="overview">Overview</h2>
<p>&#x4F53;&#x79EF;&#x5BF9;&#x8C61;&#x7EA7;SLAM</p>
<ul>
<li><p>Paper <a href="https://www.doc.ic.ac.uk/~sleutene/publications/fusion_plusplus_3dv_camera_ready.pdf" target="_blank">PDF</a></p>
</li>
<li><p><a href="https://github.com/matterport/Mask_RCNN" target="_blank">matterport/Mask_RCNN</a>
This is an implementation of Mask R-CNN on Python 3, Keras, and TensorFlow. The model generates bounding boxes and segmentation masks for each instance of an object in the image. It&apos;s based on Feature Pyramid Network (FPN) and a ResNet101 backbone.</p>
</li>
<li><a href="https://github.com/andyzeng/tsdf-fusion" target="_blank">andyzeng/tsdf-fusion</a></li>
<li><p><a href="https://github.com/tensorpack/tensorpack" target="_blank">tensorpack/tensorpack</a></p>
</li>
<li><p>Demo-Youtube</p>
</li>
</ul>
<iframe width="640" height="480" src="https://www.youtube.com/embed/2luKNC03x4k" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<ul>
<li>cite:</li>
</ul>
<p>McCormac, John, et al. &quot;Fusion++: Volumetric object-level slam.&quot; 2018 International Conference on 3D Vision (3DV). IEEE, 2018.</p>
<ul>
<li>Authors</li>
</ul>
<p>John McCormac&#x2217; Ronald Clark&#x2217; Michael Bloesch Andrew J. Davison Stefan Leutenegger
Dyson Robotics Laboratory
Department of Computing, Imperial College London</p>
<h2 id="abstract">Abstract</h2>
<p>&#x6211;&#x4EEC;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x4E2A;&#x5728;&#x7EBF;&#x5BF9;&#x8C61;&#x7EA7;SLAM&#x7CFB;&#x7EDF;,&#x6301;&#x4E45;&#x4E14;&#x51C6;&#x786E;&#x7684;&#x6784;&#x5EFA;&#x4EFB;&#x610F;&#x91CD;&#x5EFA;&#x5BF9;&#x8C61;&#x7684;3D&#x56FE;&#x5F62;&#x56FE;(graph map)&#x3002;
&#x5F53;RGB-D&#x76F8;&#x673A;&#x6D4F;&#x89C8;&#x65F6;&#x4E00;&#x4E2A;&#x6742;&#x4E71;&#x7684;&#x5BA4;&#x5185;&#x573A;&#x666F;&#xFF0C;Mask-RCNN instance segmentations &#x88AB;&#x7528;&#x4E8E;&#x521D;&#x59CB;&#x5316;&#x7D27;&#x51D1;&#x7684;&#x6BCF;&#x5BF9;&#x8C61;&#x5177;&#x6709;&#x5BF9;&#x8C61;&#x5C3A;&#x5BF8;&#x76F8;&#x5173;&#x5206;&#x8FA8;&#x7387;&#x548C;&#x65B0;&#x9896;&#x7684;3D&#x524D;&#x666F;&#x8499;&#x7248;&#x7684;Truncated
Signed Distance Function&#xFF08;TSDF&#xFF09;&#x91CD;&#x5EFA;&#x3002;&#x91CD;&#x5EFA;&#x7684;&#x5BF9;&#x8C61;&#x5B58;&#x50A8;&#x5728;&#x53EF;&#x4F18;&#x5316;&#x7684;&#x4E2D;
6DoF&#x4F4D;&#x59FF;&#x56FE;&#xFF0C;&#x5B83;&#x662F;&#x6211;&#x4EEC;&#x552F;&#x4E00;&#x7684;&#x6301;&#x4E45;&#x5730;&#x56FE;&#x8868;&#x793A;&#x3002;&#x7269;&#x4F53;&#x901A;&#x8FC7;&#x6DF1;&#x5EA6;&#x878D;&#x5408;&#x9010;&#x6B65;&#x7EC6;&#x5316;&#xFF08;refined&#xFF09;&#xFF0C;&#x5E76;&#x7528;&#x4E8E;&#x8DDF;&#x8E2A;&#xFF0C;&#x91CD;&#x5B9A;&#x4F4D;&#x548C;&#x9589;&#x74B0;&#x68C0;&#x6D4B;&#x3002;&#x9589;&#x74B0;&#x5BFC;&#x81F4;&#x5BF9;&#x8C61;&#x5B9E;&#x4F8B;&#x7684;&#x76F8;&#x5BF9;&#x59FF;&#x52BF;&#x4F30;&#x8BA1;&#x7684;&#x8C03;&#x6574;&#xFF0C;&#x4F46;&#x6CA1;&#x6709;&#x5185;&#x90E8;&#x5BF9;&#x8C61;&#xFF08;intra-object&#xFF09;&#x7684;&#x8B8A;&#x5F62;&#x3002;&#x6BCF;&#x4E2A;&#x5BF9;&#x8C61;&#x8FD8;&#x643A;&#x5E26;&#x8BED;&#x4E49;&#x4FE1;&#x606F;,&#x4E26;&#x96A8;&#x7740;&#x6642;&#x9593;&#x7684;&#x63A8;&#x79FB;&#x4E0D;&#x65AD;&#x66F4;&#x65B0;&#xFF08;refined&#xFF09;&#xFF0C;&#x548C;&#x4E00;&#x4E2A;&#x5B58;&#x5728;&#x6982;&#x7387;&#x6765;&#x89E3;&#x91CA;&#x865A;&#x5047;&#x7684;&#x5B9E;&#x4F8B;&#x7684;&#x9884;&#x6D4B;. &#x6211;&#x4EEC;&#x5728;&#x624B;&#x6301;RGB-D&#x4E0A;&#x5C55;&#x793A;&#x4E86;&#x6211;&#x4EEC;&#x7684;&#x65B9;&#x6CD5;&#x4ECE;&#x4E00;&#x4E2A;&#x5305;&#x542B;&#x5927;&#x91CF;
&#x548C;&#x5404;&#x79CD;&#x5BF9;&#x8C61;&#x5B9E;&#x4F8B;&#x6742;&#x4E71;&#x7684;&#x529E;&#x516C;&#x5BA4;&#x573A;&#x666F;&#x4E2D;&#xFF0C;&#x7A81;&#x51FA;&#x663E;&#x793A;&#x7CFB;&#x7EDF;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x95ED;&#x73AF;&#x5E76;&#x5728;&#x91CD;&#x590D;&#x7684;&#x5FAA;&#x73AF;&#x4E2D;&#x5145;&#x5206;&#x5229;&#x7528;&#x73B0;&#x6709;&#x5BF9;&#x8C61;&#x3002;
&#x6211;&#x4EEC;&#x5B9A;&#x91CF;&#x5730;&#x8BC4;&#x4F30;&#x6211;&#x4EEC;&#x7684;&#x7CFB;&#x7EDF;&#x76F8;&#x5BF9;&#x4E8E;RGB-D SLAM&#x57FA;&#x51C6;&#x7684;&#x57FA;&#x7EBF;&#x65B9;&#x6CD5;&#x7684;&#x8F68;&#x8FF9;&#x8BEF;&#x5DEE;&#xFF0C;&#x5E76;&#x5B9A;&#x6027;&#x5730;&#x6BD4;&#x8F83;YCB&#x89C6;&#x9891;&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x53D1;&#x73B0;&#x7684;&#x5BF9;&#x8C61;&#x7684;&#x91CD;&#x5EFA;&#x8D28;&#x91CF;&#x3002;&#x6027;&#x80FD;&#x8BC4;&#x4F30;&#x663E;&#x793A;&#x6211;&#x4EEC;&#x7684;&#x65B9;&#x6CD5;&#x5177;&#x6709;&#x9AD8;&#x5185;&#x5B58;&#x6548;&#x7387;&#xFF0C;&#x5E76;&#x4E14;&#x5728;4-8Hz&#xFF08;&#x4E0D;&#x5305;&#x62EC;&#x91CD;&#x5B9A;&#x4F4D;&#xFF09;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x5728;&#x7EBF;&#x8FD0;&#x884C;&#xFF0C;&#x5C3D;&#x7BA1;&#x6CA1;&#x6709;&#x5728;&#x8F6F;&#x4EF6;&#x7EA7;&#x522B;&#x8FDB;&#x884C;&#x4F18;&#x5316;&#x3002;</p>
<p>We propose an online <strong>object-level</strong> SLAM system which
builds a persistent and accurate 3D graph map of arbi-
trary reconstructed objects. As an RGB-D camera browses
a cluttered indoor scene, Mask-RCNN instance segmenta-
tions are used to initialise compact per-object Truncated
Signed Distance Function (TSDF) reconstructions with ob-
ject size-dependent resolutions and a novel 3D foreground
mask. Reconstructed objects are stored in an optimisable
6DoF pose graph which is our only persistent map repre-
sentation. Objects are incrementally refined via depth fu-
sion, and are used for tracking, relocalisation and loop clo-
sure detection. Loop closures cause adjustments in the rel-
ative pose estimates of object instances, but no intra-object
warping. Each object also carries semantic information
which is refined over time and an existence probability to
account for spurious instance predictions.</p>
<p>We demonstrate our approach on a hand-held RGB-D
sequence from a cluttered office scene with a large number
and variety of object instances, highlighting how the sys-
tem closes loops and makes good use of existing objects on
repeated loops.</p>
<p>We quantitatively evaluate the trajectory er-
ror of our system against a baseline approach on the RGB-
D SLAM benchmark, and qualitatively compare reconstruc-
tion quality of discovered objects on the YCB video dataset.
Performance evaluation shows our approach is highly mem-
ory efficient and runs online at 4-8Hz (excluding relocalisa-
tion) despite not being optimised at the software level.</p>
<h2 id="introduction">Introduction</h2>
<p>Indoor scene understanding and 3D mapping is a foundational technology that can enable autonomous real-world
robotic task completion and also provide a common interface for more intelligent and intuitive <strong>human-map and
human-robot interactions</strong>. To enable this requires a careful
choice of map representation. One particularly useful repre-
sentation is to build an <strong>object-oriented map</strong>. We argue this
is a natural and efficient way to represent the things that are
most important for robotic scene understanding, planning
and interaction; and it is also highly suitable as the basis for
human-robot communication.</p>
<p><strong>Limitations</strong>:</p>
<p>This approach also naturally paves the way towards interaction and dynamic object reasoning, although our system currently assumes a static environment and does not yet aim to track individual dynamic objects.</p>
 <link rel="stylesheet" type="text/css" href="https://storage.googleapis.com/app.klipse.tech/css/codemirror.css"> <script>     window.klipse_settings = {         selector: ".language-klipse, .lang-eval-clojure",         selector_eval_js: ".lang-eval-js",         selector_eval_python_client: ".lang-eval-python",         selector_eval_php: ".lang-eval-php",         selector_eval_scheme: ".lang-eval-scheme",         selector_eval_ruby: ".lang-eval-ruby",         selector_reagent: ".lang-reagent",        selector_google_charts: ".lang-google-chart",        selector_es2017: ".lang-eval-es2017",        selector_jsx: ".lang-eval-jsx",        selector_transpile_jsx: ".lang-transpile-jsx",        selector_render_jsx: ".lang-render-jsx",        selector_react: ".lang-react",        selector_eval_markdown: ".lang-render-markdown",        selector_eval_lambdaway: ".lang-render-lambdaway",        selector_eval_cpp: ".lang-eval-cpp",        selector_eval_html: ".lang-render-html",        selector_sql: ".lang-eval-sql",        selector_brainfuck: "lang-eval-brainfuck",        selector_js: ".lang-transpile-cljs"    }; </script> <script src="https://storage.googleapis.com/app.klipse.tech/plugin/js/klipse_plugin.js"></script>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="slam-with-objects-using-a-nonparametric-pose-graph.html" class="navigation navigation-prev " aria-label="Previous page: Slam with objects using a nonparametric pose graph">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="SLAM++.html" class="navigation navigation-next " aria-label="Next page: SLAM++">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Fusion++","level":"3.3","depth":1,"next":{"title":"SLAM++","level":"3.4","depth":1,"path":"SLAM++.md","ref":"SLAM++.md","articles":[]},"previous":{"title":"Slam with objects using a nonparametric pose graph","level":"3.2","depth":1,"path":"slam-with-objects-using-a-nonparametric-pose-graph.md","ref":"slam-with-objects-using-a-nonparametric-pose-graph.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{"_pictures":[{"backlink":"SLAM-Resources.html#fig1.3.1","level":"1.3","list_caption":"Figure: Georg Klein","alt":"Georg Klein","nro":1,"url":"http://www.robots.ox.ac.uk/~gk/imgs/georg_klein_136.jpg","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Georg Klein","attributes":{},"skip":false,"key":"1.3.1"},{"backlink":"SLAM++.html#fig3.4.1","level":"3.4","list_caption":"Figure: center 60%","alt":"center 60%","nro":2,"url":"/Assets/images/papers/SLAM++/SLAM++-RealTimeObjectDetection.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"center 60%","attributes":{},"skip":false,"key":"3.4.1"},{"backlink":"SLAM++.html#fig3.4.2","level":"3.4","list_caption":"Figure: 50% center","alt":"50% center","nro":3,"url":"/Assets/images/papers/SLAM++/ICP_breif_description.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"50% center","attributes":{},"skip":false,"key":"3.4.2"},{"backlink":"SLAM++.html#fig3.4.3","level":"3.4","list_caption":"Figure: center 80%","alt":"center 80%","nro":4,"url":"/Assets/images/papers/SLAM++/AugmentedRealityWithObjects.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"center 80%","attributes":{},"skip":false,"key":"3.4.3"},{"backlink":"kinect2.html#fig7.2.1","level":"7.2","list_caption":"Figure: Kinetic2 Demo","alt":"Kinetic2 Demo","nro":5,"url":"../Assets/Images/Kinetic2_Protonect_Test_Result.jpg","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kinetic2 Demo","attributes":{},"skip":false,"key":"7.2.1"},{"backlink":"slam-course-robot-mapping.html#fig8.3.1","level":"8.3","list_caption":"Figure: Localization Example","alt":"Localization Example","nro":6,"url":"/assets/Estimate the Robot Pose.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Localization Example","attributes":{},"skip":false,"key":"8.3.1"},{"backlink":"slam-course-robot-mapping.html#fig8.3.2","level":"8.3","list_caption":"Figure: Localization Example","alt":"Localization Example","nro":7,"url":"/assets/Estimate Landmarks.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Localization Example","attributes":{},"skip":false,"key":"8.3.2"},{"backlink":"slam-course-robot-mapping.html#fig8.3.3","level":"8.3","list_caption":"Figure: Localization Example","alt":"Localization Example","nro":8,"url":"/assets/Screen Shot 2019-01-28 at 7.20.23.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Localization Example","attributes":{},"skip":false,"key":"8.3.3"},{"backlink":"slam-course-robot-mapping.html#fig8.3.4","level":"8.3","list_caption":"Figure: Uncertainty Representation","alt":"Uncertainty Representation","nro":9,"url":"/assets/Screen Shot 2019-01-28 at 8.14.04.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Uncertainty Representation","attributes":{},"skip":false,"key":"8.3.4"},{"backlink":"slam-course-robot-mapping.html#fig8.3.5","level":"8.3","list_caption":"Figure: SLAM in the Probabilistic World","alt":"SLAM in the Probabilistic World","nro":10,"url":"/assets/Screen Shot 2019-01-28 at 8.39.27.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"SLAM in the Probabilistic World","attributes":{},"skip":false,"key":"8.3.5"},{"backlink":"slam-course-robot-mapping.html#fig8.3.6","level":"8.3","list_caption":"Figure: Motion and Observation Model","alt":"Motion and Observation Model","nro":11,"url":"assets/markdown-img-paste-20190128111722554.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Motion and Observation Model","attributes":{},"skip":false,"key":"8.3.6"},{"backlink":"slam-course-robot-mapping.html#fig8.3.7","level":"8.3","list_caption":"Figure: Motion Model","alt":"Motion Model","nro":12,"url":"assets/markdown-img-paste-20190128112352359.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Motion Model","attributes":{},"skip":false,"key":"8.3.7"},{"backlink":"slam-course-robot-mapping.html#fig8.3.8","level":"8.3","list_caption":"Figure: Motion Model Example","alt":"Motion Model Example","nro":13,"url":"assets/markdown-img-paste-20190128111616903.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Motion Model Example","attributes":{},"skip":false,"key":"8.3.8"},{"backlink":"slam-course-robot-mapping.html#fig8.3.9","level":"8.3","list_caption":"Figure: Standard Odometry Model","alt":"Standard Odometry Model","nro":14,"url":"assets/markdown-img-paste-20190128112933104.png","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Standard Odometry Model","attributes":{},"skip":false,"key":"8.3.9"},{"backlink":"slam-course-robot-mapping.html#fig8.3.10","level":"8.3","list_caption":"Figure: Observation Model","alt":"Observation Model","nro":15,"url":"assets/markdown-img-paste-20190128114114463.png","index":10,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Observation Model","attributes":{},"skip":false,"key":"8.3.10"},{"backlink":"slam-course-robot-mapping.html#fig8.3.11","level":"8.3","list_caption":"Figure: Observation Model Examples","alt":"Observation Model Examples","nro":16,"url":"assets/markdown-img-paste-20190128114225690.png","index":11,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Observation Model Examples","attributes":{},"skip":false,"key":"8.3.11"}]},"plugins":["multipart","youtube","image-captions","disqus","donate","advanced-emoji","splitter","mermaid-gb3","puml","graph","chart","simple-page-toc","sitemap-general","todo","terminal","copy-code-button","include-csv","klipse","scripts","page-numbering","codeblock-filename","katex","livereload"],"pluginsConfig":{"include-csv":{},"disqus":{"useIdentifier":false,"shortName":"https-yubaoliu-gitbooks-io"},"youtube":{},"puml":{},"livereload":{},"simple-page-toc":{},"todo":{},"splitter":{},"scripts":{"files":["./myscript.js"]},"search":{},"multipart":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"graph":{},"donate":{"alipay":"","alipayText":"支付宝捐赠","button":"Donate","title":"","wechat":"https://i.imgur.com/nUAbMLG.png","wechatText":"微信捐赠"},"sitemap-general":{"prefix":"https://yubaoliu.gitbooks.io"},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mermaid-gb3":{},"codeblock-filename":{},"copy-code-button":{},"klipse":{"myConfigKey":"it's the default value"},"page-numbering":{"chapterFormat":"Chapter #chapno#&nbsp;&nbsp;&nbsp;#title# ||| #chapno#&nbsp;&nbsp;&nbsp;#title#","forceMultipleParts":false,"skipReadme":false},"advanced-emoji":{"embedEmojis":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"terminal":{"copyButtons":true,"fade":false,"style":"flat"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"chart":{"type":"c3"},"image-captions":{"caption":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","variable_name":"_pictures"}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"Fusion++.md","mtime":"2019-01-25T02:46:52.864Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-01-30T02:01:12.728Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-donate/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-terminal/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-scripts/9f6c471c34065cdbabd862bf00229682-myscript.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    <script src="gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>

    </body>
</html>

